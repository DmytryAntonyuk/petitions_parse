{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<script>\n",
    "    // AUTORUN ALL CELLS ON NOTEBOOK-LOAD!\n",
    "    require(\n",
    "        ['base/js/namespace', 'jquery'], \n",
    "        function(jupyter, $) {\n",
    "            $(jupyter.events).on(\"kernel_ready.Kernel\", function () {\n",
    "                console.log(\"Auto-running all cells-below...\");\n",
    "                jupyter.actions.call('jupyter-notebook:run-all-cells-below');\n",
    "                jupyter.actions.call('jupyter-notebook:save-notebook');\n",
    "            });\n",
    "        }\n",
    "    );\n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the is you need to put pet number\n",
    "Put_petition_number_here = 111140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import matplotlib.pyplot as plt #for form dataframe from Pyth series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_number = str(Put_petition_number_here) #make a variable for page number\n",
    "url = f'https://petition.president.gov.ua/petition/{pet_number}'\n",
    "r_html = requests.get(url).text  #its request for HTML into text for getting last page namber\n",
    " # basic knowleg for parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pages_count(html): # functions for counting last page in petition\n",
    "        html=r_html\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        page_obj = soup.find_all('a', class_='pag_link')\n",
    "        last_page = page_obj[-2].get_text()\n",
    "        return last_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse():\n",
    "    r_statuse_code = requests.get(f'{url}/votes/1/json')\n",
    "    if r_statuse_code.status_code == 200:\n",
    "        vote = []\n",
    "        last_page=int(get_pages_count(r_html))\n",
    "        for page in range(1,last_page+1):\n",
    "            print(f'Парсинг страницы {page} из {last_page+1} ...')\n",
    "            URL_json= f'https://petition.president.gov.ua/petition/{pet_number}/votes/{page}/json'\n",
    "            r = requests.get(URL_json).json()\n",
    "            soup = BeautifulSoup(r['table_html'])\n",
    "            soup_names=soup.find_all('div', class_='table_cell name')\n",
    "            soup_numbers = soup.find_all('div', class_='table_cell number')\n",
    "            soup_dates=soup.find_all('div', class_='table_cell date')\n",
    "            names = []\n",
    "            dates = []\n",
    "            numbers = []\n",
    "            for number_item,name_item, data_item in zip(soup_numbers,soup_names,soup_dates):\n",
    "                names.append(name_item.get_text())\n",
    "                dates.append(data_item.get_text())\n",
    "                numbers.append(number_item.get_text())\n",
    "            numbers = pd.Series(numbers)\n",
    "            names = pd.Series(names)\n",
    "            dates = pd.Series(dates)\n",
    "            df = { 'Number': numbers, 'Name': names,'Date':dates }\n",
    "            result = pd.DataFrame(df)\n",
    "            vote.append(result)\n",
    "    else:\n",
    "        print('Error')\n",
    "    return(pd.concat(vote))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = parse()\n",
    "parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed['Number']= parsed['Number'].str.replace('.','')\n",
    "df = parsed.set_index('Number')\n",
    "def replace_all (text):\n",
    "    for ch in ['а', 'е', 'и', 'і', 'о', 'у', 'є', 'ю', 'я', \"'\", ' ']:\n",
    "        text = text.str.replace(ch,'')\n",
    "    return text\n",
    "df['replaced'] = replace_all (df['Name'].str.lower())\n",
    "#df.Description.str.lower()\n",
    "df.to_csv(\"votering\",sep=',',encoding= 'UTF8' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example  = pd.read_csv(r\"C:\\Users\\Dima\\Desktop\\Parsinb\\example.txt\", sep = \"|\", encoding='windows-1251')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example[['Name','PP']] = example.\n",
    "#df[['First','Last']] = df.Name.str.split(\" \",expand=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
